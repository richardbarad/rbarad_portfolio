{
  "hash": "13bad86e3a1a37ded9cb9de685fd6744",
  "result": {
    "markdown": "---\ntitle: \"Global Dashboard for Hostspot Indentification - Famine Early Warning Systems Network\"\nauthor: \"Richard Barad\"\nimage: gdhi_screenshoot.png\ndate: \"2024-01-01\"\ncategories: [Food Security, Python, ArcGIS, Power BI]\nformat: \n  html:\n    toc: true\n    code-fold: true\n    fontsize: 11pt\nexecute:\n  eval: false\nabout:\n  id: hero-heading\n  image-width: 0em\n  template: solana\n  links:\n    - icon: clipboard-data\n      text: Power BI Dashboard\n      href: https://app.powerbi.com/view?r=eyJrIjoiYTRiMDQ2ZjEtMmJiOS00MmM5LWE0MGQtNGEzM2I2YzdkZTY2IiwidCI6IjdjMWYyNGE2LTdkMzktNDUyYy04MjM3LTA3MjZlM2IxOWE3MyIsImMiOjF9\n    - icon: map\n      text: ArcGIS Online Maps\n      href: https://fewsnet.maps.arcgis.com/apps/instant/portfolio/index.html?appid=6c4160dd9fa848b8be366ba8016262df\n    - icon: camera-video\n      text: GDHI Video Overview\n      href: https://drive.google.com/file/d/1r9UZJgxZ7TmW8p65OjePAp8aSAyTdo2a/view?usp=sharing\n---\n\n# Overview\n\nThe Global Dashboard for Hotspot Identification (GDHI) is a screening tool used for by the Famine Early Warning System Network to identify potential food security areas of concern in the Horn of Africa. The GDHI provides FEWS NET with a rough estimate of potential food security durring the upcoming year. In my role as a Livelihood Monitoring Analyst at FEWS NET I was responsible for helping to build and run the GDHI on a monthly basis. The GDHI was developed as an Excel based tool, and historically analysts had to review the results of the analysis by e-mailing an Excel file with the results to everyone who needed them. \nIn order to make the results more accessible I set-up a data visualization system to display the results using Microsoft Power BI and ArcGIS Online. Additionally, I developed a Python script that reads the results from an Excel file, transforms the results into the formats needed by Power BI and ArcGIS Online, and publishes the results. Browse below to view the python script, ArcGIS Online Maps, and Power BI Dashboard. Links to view the Power BI Dashboard and ArcGIS Online Maps in full screen are available above. \n\nA link to a video overview of the GDHI is also included above. Please watch the video if you are interested in learning more about how the GDHI works and how FEWS NET uses the map and dashboard tools I created.\n\n# Python Script\n\nThe script below was written to automate the process of publishing the GDHI results to Power BI and ArcGIS Online. The script is written using arcpy, pandas, and datetime libraries and includes the following steps:\n\n1) Update the ArcGIS Online Feature class\n    * Extracts the GDHI results from excel file and imports the results to Pandas Dataframe.\n    * Merge together the Ethiopia results with the Kenya, Uganda, and Somalia GDHI results - Ethiopia results are stored in a separate file.\n    * Exports pandas data frame to a .csv file, join .csv to a feature class, and export the joined result.\n    * Sets appropriate aliases for the feature class fields \n    * Add feature class to a Pro project, and remove feature class from previous month\n    * Publish updated ArcGIS Pro map to ArcGIS Online\n    \n2) Update the csv files used in the Power BI Dashboard:\n    * Get current outlook and year from Excel Interface file\n    * Create a dictionary with the time range associated with each analysis quarter based on the selected outlook and year run\n    * Flatten results using Pandas to create a flat file on population by Phase, by quarter for each area of analysis - export CSV results\n    * Flatten results using Pandas to create a flat file on MT needs by quarter for ach area of analysis - export CSV results\n    \nClick the code button bellow to view the full script!\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport datetime\nfrom dateutil.relativedelta import relativedelta\nimport arcpy\nimport openpyxl\nfrom arcgis.gis import GIS\n\narcpy.env.overwriteOutput = True\n\n#This is  the directory where the GDHI files for the current month are saved\nKE_SO_UG_GDHI=r'C:\\Users\\rbarad\\OneDrive - Chemonics\\10.GDHI\\01.EA_Monthly_Runs\\02.GDHI-tool\\2023\\05_RB\\KE_UG_SO\\run2' #Path to GDHI Excel files for KE, UG, SO for 2nd run\nET_GDHI=r'C:\\Users\\rbarad\\OneDrive - Chemonics\\10.GDHI\\01.EA_Monthly_Runs\\02.GDHI-tool\\2023\\05_RB\\ET\\GDHI_Outlook' #Path to GDHI results files for ET\nET_GDHI_NOPSNP='NatLIAS_res_summ_Outlook_NOPSNP.xlsm' #Name of results file without PSNP\nET_GDHI_PSNP='NatLIAS_res_summ_Outlook.xlsm' #Name of results file with PSNP\n\n#Edit this to select when adminstrative areas in Ethiopia should be greyed out\nadmin2_units = ['Zone 1','Zone 2','Zone 4','North Gondar', 'Wag Himra', 'North Wollo'] #Must match spelling used in shapefile\nadmin1_units = ['Tigray'] #Must match spelling used in shapefile, if you want to exclude an entire admin1 unit specify it here\n\n#Set month and year when analysis is for\nmonth=5\nyear=2023\n\nparams= {'input_featureclass':'SO_UG_KE_ET_GDHI_Admin_LHZ_simp', #Name of Feature class to join GDHI results to - must be stored in Pro Project GDB which is specified as the arcpy.env.workspace\n         'sharepoint_folder':r'C:\\Users\\rbarad\\OneDrive - Chemonics\\10.GDHI\\01.EA_Monthly_Runs\\01.SharePoint', #Location of Share Point folder containing ArcGIS Pro Project and Power BI Files\n         'username':'FEWS_NET', #username for AGOL\n         'password':'FewsNet2021', #Password goes here\n         'service':'GDHI_results'} #Name of service in AGOL to overwrite\n\noutlookstart = {1: 1,\n                2: 4,\n                3: 10}\n\n#Set the file path to the sharepoint folder, Project GDB, and Pro Project\nsharepoint_folder = params['sharepoint_folder']\narcpy.env.workspace=os.path.join(sharepoint_folder,'GDHI_Results.gdb') #Set arcgis workspace\npro_project = os.path.join(sharepoint_folder,'GDHI_Results.aprx') #Set path to project\n\n#Dictionary Contains Aliases to assign to each column in the feature class\nalias_list= {'Q1_IPC_Max': 'Q1 Max Indicative Household Phase','Q1_IPC_Area': 'Q1 Indicative Area Phase','Q1_3plus': 'Q1 Pop in IPC Phase 3+','Q1_MT': 'Q1 Metric Tons of aid',\n             'Q2_IPC_Max': 'Q2 Max Indicative Household Phase','Q2_IPC_Area': 'Q2 Indicative Area Phase','Q2_3plus': 'Q2 Pop in IPC Phase 3+','Q2_MT': 'Q2 Metric Tons of aid',\n             'Q3_IPC_Max': 'Q3 Max Indicative Household Phase','Q3_IPC_Area': 'Q3 Indicative Area Phase','Q3_3plus': 'Q3 Pop in IPC Phase 3+', 'Q3_MT': 'Q3 Metric Tons of aid',\n             'IPC_Max': 'Highest Indicative Household Phase','IPC_Area_Max':'Highest Indicative Area Phase', 'IPC_Area_Avg': 'Average Indicative Phase','MT_Total': 'Total Metric tons (Q1 - Q3)',\n             'Total_pop':'Total Population','Kg_Per_capita':'Kilograms per capita'}\n\n#Class of functions to read results into a pandas dataframes\nclass read_merge_data():\n    \n    def read_ke_so_ug(kesoug_results):\n        print('Read KE,SO,UG Results Data')\n        os.chdir(kesoug_results)\n        results = pd.DataFrame(pd.read_excel('NatLIAS_res_summ.xlsx',sheet_name='Mapping',skiprows=1,nrows=311)) #Read results from GDHI into a Dataframe\n        return results\n    \n    def read_et(et_folder,filename):\n        print('Read ET Results Data')\n        os.chdir(et_folder)\n        results = pd.DataFrame(pd.read_excel(filename,sheet_name='Mapping_Meth2',skiprows=1,nrows=875)) #Read results from GDHI into a Dataframe\n        results=results[results['FNID'].notnull()]\n        results = results[~((results['Admin2'].isin(admin2_units)) | (results['Admin1'].isin(admin1_units)))] #Remove Zone 1, Zone 2, and Zone 4 of Afar and Tigray since GDHI Not Valid there\n        results['COUNTRY'] = 'Ethiopia'\n        return results\n    \n    def merge(kesoug_results,et_folder,et_filename):\n        results1 = read_merge_data.read_ke_so_ug(kesoug_results)\n        results2 = read_merge_data.read_et(et_folder,et_filename)\n        print('Merge Data')\n        results = pd.concat([results1,results2],ignore_index=True)\n        return results\n\nresults = read_merge_data.merge(KE_SO_UG_GDHI,ET_GDHI,ET_GDHI_PSNP) #Read results with PSNP\nresults_NOPSNP = read_merge_data.read_et(ET_GDHI,ET_GDHI_NOPSNP) #Read results without PSNP\n\ndef create_quarter_IPC_list(): #Function creates a list of collumns names for the combinations of IPC Phases and quarter (i.e: Q1_IPC1, Q1_IPC2, Q1_IPC3, Q1_IPC4, Q1_IPC5, Q2_IPC1, etc.) \n    quarters=['Q1','Q2','Q3']\n    quarters_phase_list = []\n    IPC_Phase = range(1,6)\n    for q in quarters:\n        for p in IPC_Phase:\n            quarter_phase = q + '_IPC' + str(p)\n            quarters_phase_list.append(quarter_phase)\n    return quarters_phase_list\n\ndef create_quarter_variable_list(): #Function create list of data column names for each quarter - includes MT per quarter, Area Phase Clasification, Highest Phase Classification, and Metric Tons (MT) \n    quarters=['Q1','Q2','Q3']\n    fields = ['IPC_Max','IPC_Area','3plus','MT']\n    quarter_field_list = []\n    for q in quarters:\n        for f in fields:\n            field = q + \"_\" + f\n            quarter_field_list.append(field)\n    return quarter_field_list\n    \ndef create_results_featureclass(df,output_name): #Function to create featureclass, 1st input is a df containing GDHI results, second input is name of output featureclass\n    print(\"Create Featureclass for GDHI results...\")\n    #Save copy of GDHI Mapping units in memory\n    gdhi_shapes = os.path.join('in_memory',params['input_featureclass'])\n    arcpy.management.CopyFeatures(params[\"input_featureclass\"], gdhi_shapes) #Create copy of GDHI shapes in-memory\n    #Convert GDHI results to a .csv and join results to in memory featureclass, export featureclass to disk, delete .csv once complete\n    df.to_csv('NATLIAS_results.csv')\n    results_csv= os.getcwd() + os.sep + \"NATLIAS_results.csv\"\n    results_table = arcpy.conversion.TableToTable(results_csv, arcpy.env.workspace, 'results') #Had to convert csv to a table because JoinField Function was not working with .csv in Pro 3.0.\n    arcpy.JoinField_management(gdhi_shapes, 'FNID', results_table, 'FNID',fields_join) #Append data to in-memory featureclass\n    arcpy.management.CopyFeatures(gdhi_shapes, output_name)\n    arcpy.Delete_management(\"results\")\n    os.remove(results_csv)\n\ndef set_aliases(output): #Set aliases\n    for field in fields_join:\n        print(\"Update Alias for \" + field)\n        arcpy.AlterField_management(output, field, new_field_alias=alias_list[field])\n\n#Create featureclass for ESRI story map with & without PSNP using defined functions\nfields_join = create_quarter_variable_list() + ['IPC_Max','IPC_Area_Max','IPC_Area_Avg','MT_Total','Total_pop','Kg_Per_capita'] #Create list of quarterly data fields using function and add average variables to list\nmonth_name = datetime.date(year, month, 1).strftime('%Y_%m')  #Create string based on month and year to use in featureclass names\n\noutput_name = 'GDHI_results_' + month_name #Set name of output feature class with PSNP\ncreate_results_featureclass(results,output_name) #Create feature class for results with PSNP\nset_aliases(output_name) #Set alias names in feature class\n\noutput_name_NOPSNP = 'GDHI_results_' + month_name + 'NOPSNP' #Set name of output feature class without PSNP\ncreate_results_featureclass(results_NOPSNP,output_name_NOPSNP) #Create feature class for results without PSNP\nset_aliases(output_name_NOPSNP) #Set alias names in feature class\n\n#Create variables for Pro Project and Map in Pro Project\naprx = arcpy.mp.ArcGISProject(pro_project)\naprxMap = aprx.listMaps(\"Map\")[0] \n\ndef update_pro_project():\n    #Add new results Featureclasses to the ArcGIS Pro Project - rename layers, but first remove old GDHI results layer from map so that map only includes one layer.\n    print(\"Update Pro Project...\")\n    lyr_path_PSNP = os.path.join(arcpy.env.workspace,output_name)\n    lyr_path_noPSNP = os.path.join(arcpy.env.workspace,output_name_NOPSNP)\n    for lyr in aprxMap.listLayers(): #Remove existing layers    \n        aprxMap.removeLayer(lyr)\n    aprxMap.addDataFromPath(lyr_path_PSNP) #Add layer\n    lyr = aprxMap.listLayers()[0] #Select first and only layer in map\n    lyr.name = 'GDHI_results' #Rename selected layer to 'GDHI_results'\n    aprxMap.addDataFromPath(lyr_path_noPSNP) #Add no PSNP Layer to map\n    move_lyr = aprxMap.listLayers('*PSNP')[0] #Select no PSNP layer\n    aprxMap.moveLayer(lyr, move_lyr, 'AFTER') #Move PSNP to be the second layer in map to keep same order\n    move_lyr.name = 'GDHI_results_NOPSNP' #Rename selected layer to 'GDHI_results_NOPSNP' to keep name the same\n    aprx.save()\n    print(\"Pro Project Updated\")\n\ndef update_AGOL():\n    #Sign in to ArcGIS Online\n    print(\"Sign in to ArcGIS Online\")\n    gis = GIS('https://www.arcgis.com', params['username'], params['password'])\n    # Set sharing draft and service definition file names\n    service = params['service']\n    sddraft_filename = os.path.join(sharepoint_folder, service + \".sddraft\")\n    sd_filename = os.path.join(sharepoint_folder, service + \".sd\")\n    # Create FeatureSharingDraft and set service properties\n    print(\"Create Sharing Draft and Service Defintion Files...\")\n    sharing_draft = aprxMap.getWebLayerSharingDraft(\"HOSTING_SERVER\", \"FEATURE\", service)\n    sharing_draft.summary = \"Results of the GDHI for \" + datetime.date(year, month, 1).strftime('%B %Y')\n    sharing_draft.overwriteExistingService = True\n    sharing_draft.portalFolder = '01. GDHI'\n    # Create Service Definition Draft file and service definition\n    sharing_draft.exportToSDDraft(sddraft_filename)\n    arcpy.StageService_server(sddraft_filename, sd_filename)\n    # Find the Service definition, update it, publish /w overwrite and set sharing and metadata\n    print(\"Search for original SD on portal…\")\n    searchData = gis.content.search(query=\"title:\"+ service + \" AND owner: \" + 'FEWS_NET', item_type=\"Service Definition\")\n    for search in searchData:\n        print(search)\n        if search.title== service:\n            print(\"Found SD: {}, ID: {} Uploading and overwriting…\".format(search.title, search.id))\n            search.update(data=sd_filename)\n            print(\"Overwriting existing feature service…\")\n            fs = search.publish(overwrite=True)\n            print(\"Finished updating: {} – ID: {}\".format(fs.title, fs.id))\n        else: \n            pass\n            print('Pass item in list')\n\n#Update Pro project and publish feature class to AGOL.\nupdate_pro_project()\nupdate_AGOL()\n#arcpy.Delete_management(\"in_memory\") #Clear arcgis memory space\n\n#Rest of script creates csv files which are used in Power Bi. Will need to open Power BI and update data source after script copmletes\n\ndef get_outlook_year_from_Excel(): #Get the outlook and year of analysis from the SO, UG, KE GDHI file.\n    os.chdir(KE_SO_UG_GDHI)\n    book = openpyxl.load_workbook('NatLIAS_interface.xlsm')\n    sheet = book.active\n    year = sheet['E9'].value\n    outlook = sheet['E7'].value\n    return[year,outlook]\n\ndef generate_ranges(): #Generate month ranges for each quarter and write results to a python dictionary, subsequently used in IPC_Phase_Clean() and IPC_MT_Clean() functions to get the month ranges for eqch quarter\n    dictionary = {}    \n    print (\"Gernerate date range for each quarter, based on selected outlook\")\n    date = get_outlook_year_from_Excel()\n    start_date= datetime.date(date[0], outlookstart[date[1]], 1) #Convert number representing month from outlook start to a date based on year, and start month of selected GDHI run\n    dictionary['Q1']= '(' + start_date.strftime(\"%b. %y\") + ' - ' + (start_date + relativedelta(months=2)).strftime(\"%b. %y\") + ')'\n    dictionary['Q2']= '(' + (start_date + relativedelta(months=3)).strftime(\"%b. %y\") + ' - ' + (start_date + relativedelta(months=5)).strftime(\"%b. %y\") + ')'\n    dictionary['Q3']= '(' + (start_date + relativedelta(months=6)).strftime(\"%b. %y\") + ' - ' + (start_date + relativedelta(months=8)).strftime(\"%b. %y\") + ')'\n    return dictionary\n\ndef IPC_Phase_Clean(df,output_name): #Flatten to create a file on population by Phase, per quarter\n   print(\"Create File for IPC Phase by Quarter\")\n   try: #This try logic is necessary because the data with PSNP does not include an LH Zone Column since it just for Ethiopia\n       df_filt = df[~df['LH Zone'].isin(['BDA','SO19','KMO'])] #Remove urban results (only needed for results with Somalia included)\n       results_org = df_filt.melt(id_vars=['FNID','COUNTRY','Admin1','Admin2','Admin3','LH Zone','Total_pop'],value_vars=create_quarter_IPC_list(),value_name='Pop',var_name='Quarter_Phase') \n   except:\n       results_org = df.melt(id_vars=['FNID','COUNTRY','Admin1','Admin2','Admin3','Total_pop'],value_vars=create_quarter_IPC_list(),value_name='Pop',var_name='Quarter_Phase')\n   results_org['Quarter'] = results_org['Quarter_Phase'].str.split(\"_\",n = 1, expand = True)[0]\n   results_org['Phase'] = results_org['Quarter_Phase'].str.split(\"_\",n = 1, expand = True)[1]\n   results_org['Quarter'] = results_org['Quarter'] + ' ' + results_org['Quarter'].map(quartertimeranges)\n   results_org['Pop'] = results_org['Pop'].round(0) #round to nearest whole person since you can not have half a person\n   results_org.drop(labels='Quarter_Phase',axis=1,inplace=True)\n   try:\n       results_org.sort_values(['COUNTRY','Admin1','Admin2','Admin3','LH Zone','Quarter','Phase'],inplace=True)\n   except:\n       results_org.sort_values(['COUNTRY','Admin1','Admin2','Admin3','Quarter','Phase'],inplace=True)\n   results_org.to_csv(output_name)\n\ndef IPC_MT_Clean(df,output_name): #Flatten to create a file on MT by quarter\n    print(\"Create File for MT Needs by Quarter\")\n    try: #This try logic is necessary because the data with PSNP does not include an LH Zone Column since it just for Ethiopia\n        df_filt = df[~df['LH Zone'].isin(['BDA','SO19','KMO'])] #Remove urban results (only needed for results with Somalia included)\n        results_org_MT = df_filt.melt(id_vars=['FNID','COUNTRY','Admin1','Admin2','Admin3','LH Zone','Total_pop'],value_vars=['Q1_MT','Q2_MT','Q3_MT'],value_name='MT',var_name='Quarter_MT')\n    except:\n        results_org_MT = df.melt(id_vars=['FNID','COUNTRY','Admin1','Admin2','Admin3','Total_pop'],value_vars=['Q1_MT','Q2_MT','Q3_MT'],value_name='MT',var_name='Quarter_MT')\n    results_org_MT['Quarter'] = results_org_MT['Quarter_MT'].str.split(\"_\",n = 1, expand = True)[0]\n    results_org_MT['Quarter_detail'] = results_org_MT['Quarter'] + ' ' + results_org_MT['Quarter'].map(quartertimeranges)\n    results_org_MT.drop(labels='Quarter_MT',axis=1,inplace=True)\n    try: #This try logic is necessary because the data with PSNP does not include an LH Zone Column since it just for Ethiopia\n        results_org_MT.sort_values(['COUNTRY','Admin1','Admin2','Admin3','LH Zone','Quarter',],inplace=True)\n    except:\n        results_org_MT.sort_values(['COUNTRY','Admin1','Admin2','Admin3','Quarter',],inplace=True)\n    results_org_MT.to_csv(output_name)\n\n#Create csv files for PowerBI - save to Sharepoint folder\nquartertimeranges = generate_ranges()\nos.chdir(sharepoint_folder) # Change directory to SharePoint folder so that csv files are exported here - same path to csv file each time\n\n#Create Power BI files for results with PSNP\nIPC_Phase_Clean(results,'IPC_Phase.csv')\nIPC_MT_Clean(results,'MT_Needs.csv')\n\n#Create PowerBI files for results without PSNP\nIPC_Phase_Clean(results_NOPSNP,'IPC_Phase_noPSNP.csv')\nIPC_MT_Clean(results_NOPSNP,'MT_Needs_noPSNP.csv')\n\nprint(\"Script Complete\")\n```\n:::\n\n\n# ArcGIS Online Maps\n\nThe maps below are created in ArcGIS Online to help showcase the results of the GDHI. The included maps show the highest indicative IPC Phase and the highest Indicative Household IPC Phase estimated by the GDHI across the analysis period. There is also a map showing the total Metric Tons of Assistance needed to fill deficits across the analysis period. The maps are combined into a single application using instant app tools available in ArcGIS Online. Click on the arrows at the bottom of the page to toggle between the different available maps.\n\n\n```{=html}\n<iframe \n  width=\"100%\" \n  height=\"500\" \n  src=\"https://fewsnet.maps.arcgis.com/apps/instant/portfolio/index.html?appid=6c4160dd9fa848b8be366ba8016262df\">\n</iframe>\n```\n\n\n# Power BI Dashboard\n\nI created the Power BI Dashboard below to show the results of the GDHI Analysis. The Dashboard provides information on the estimated population in each IPC Phase and includes visualizations showing the average population in IPC Phase 2+ by administrative unit across the period of analysis. The dashboard also provides information on the estimate Metric Tons of food assistance needed to fill food security deficits by quarter. You can click on the arrows at the bottom of the dashboard to see results for different countries. \n\n\n```{=html}\n<iframe \n  width=\"100%\" \n  height=\"500\" \n  src=\"https://app.powerbi.com/view?r=eyJrIjoiYTRiMDQ2ZjEtMmJiOS00MmM5LWE0MGQtNGEzM2I2YzdkZTY2IiwidCI6IjdjMWYyNGE2LTdkMzktNDUyYy04MjM3LTA3MjZlM2IxOWE3MyIsImMiOjF9\">\n</iframe>\n```\n\n",
    "supporting": [
      "GDHI_files"
    ],
    "filters": [],
    "includes": {}
  }
}